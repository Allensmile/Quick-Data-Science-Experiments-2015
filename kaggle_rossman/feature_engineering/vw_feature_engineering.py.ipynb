{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_features(features, data):\n",
    "    # remove NaNs\n",
    "    data.fillna(0, inplace=True)\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "    # Use some properties directly\n",
    "    features.extend(['CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n",
    "\n",
    "    # Label encode some features\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "    \n",
    "    storeTypes = pd.get_dummies(data['StoreType'], prefix='StoreType')\n",
    "    features.extend(storeTypes.columns)\n",
    "    data = data.join(storeTypes)\n",
    "    \n",
    "    assortments = pd.get_dummies(data['Assortment'], prefix='Assortment')\n",
    "    features.extend(assortments.columns)\n",
    "    data = data.join(assortments)\n",
    "    \n",
    "    stateHolidays = pd.get_dummies(data['StateHoliday'], prefix='StateHoliday')\n",
    "    features.extend(stateHolidays.columns)\n",
    "    data = data.join(stateHolidays)\n",
    "    \n",
    "    \n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "    years = pd.get_dummies(data['Year'], prefix='Year')\n",
    "    features.extend(years.columns)\n",
    "    data = data.join(years)\n",
    "    \n",
    "    months = pd.get_dummies(data['Month'], prefix='Month')\n",
    "    features.extend(months.columns)\n",
    "    data = data.join(months)\n",
    "    \n",
    "    days = pd.get_dummies(data['Day'], prefix='Day')\n",
    "    features.extend(days.columns)\n",
    "    data = data.join(days)\n",
    "    \n",
    "    dayOfWeeks = pd.get_dummies(data['DayOfWeek'], prefix='DayOfWeek')\n",
    "    features.extend(dayOfWeeks.columns)\n",
    "    data = data.join(dayOfWeeks)\n",
    "    \n",
    "    weekOfYears = pd.get_dummies(data['WeekOfYear'], prefix='WeekOfYear')\n",
    "    features.extend(weekOfYears.columns)\n",
    "    data = data.join(weekOfYears)\n",
    "    \n",
    "\n",
    "    features.append('CompetitionOpen')\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n",
    "        (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n",
    "        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "\n",
    "    features.append('IsPromoMonth')\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(month2str)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "    return data\n",
    "\n",
    "                \n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),\n",
    "        'CompetitionOpenSinceMonth': np.dtype(int),\n",
    "        'StateHoliday': np.dtype(str),\n",
    "        'Promo2SinceWeek': np.dtype(int),\n",
    "        'SchoolHoliday': np.dtype(float),\n",
    "        'PromoInterval': np.dtype(str)}\n",
    "train = pd.read_csv(\"../data/train.csv\", parse_dates=[2], dtype=types)\n",
    "test = pd.read_csv(\"../data/test.csv\", parse_dates=[3], dtype=types)\n",
    "store = pd.read_csv(\"../data/store.csv\")\n",
    "\n",
    "train.fillna(1, inplace=True)\n",
    "test.fillna(1, inplace=True)\n",
    "\n",
    "train = train[train[\"Open\"] != 0]\n",
    "train = train[train[\"Sales\"] > 0]\n",
    "\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n",
    "\n",
    "features = []\n",
    "\n",
    "train = build_features(features, train)\n",
    "test = build_features([], test)\n",
    "for feature in features:\n",
    "    if feature not in test.columns:\n",
    "        test[feature] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CompetitionDistance',\n",
       " 'Promo',\n",
       " 'Promo2',\n",
       " 'SchoolHoliday',\n",
       " 'StoreType_1',\n",
       " 'StoreType_2',\n",
       " 'StoreType_3',\n",
       " 'StoreType_4',\n",
       " 'Assortment_1',\n",
       " 'Assortment_2',\n",
       " 'Assortment_3',\n",
       " 'StateHoliday_0',\n",
       " 'StateHoliday_1',\n",
       " 'StateHoliday_2',\n",
       " 'StateHoliday_3',\n",
       " 'Year_2013',\n",
       " 'Year_2014',\n",
       " 'Year_2015',\n",
       " 'Month_1',\n",
       " 'Month_2',\n",
       " 'Month_3',\n",
       " 'Month_4',\n",
       " 'Month_5',\n",
       " 'Month_6',\n",
       " 'Month_7',\n",
       " 'Month_8',\n",
       " 'Month_9',\n",
       " 'Month_10',\n",
       " 'Month_11',\n",
       " 'Month_12',\n",
       " 'Day_1',\n",
       " 'Day_2',\n",
       " 'Day_3',\n",
       " 'Day_4',\n",
       " 'Day_5',\n",
       " 'Day_6',\n",
       " 'Day_7',\n",
       " 'Day_8',\n",
       " 'Day_9',\n",
       " 'Day_10',\n",
       " 'Day_11',\n",
       " 'Day_12',\n",
       " 'Day_13',\n",
       " 'Day_14',\n",
       " 'Day_15',\n",
       " 'Day_16',\n",
       " 'Day_17',\n",
       " 'Day_18',\n",
       " 'Day_19',\n",
       " 'Day_20',\n",
       " 'Day_21',\n",
       " 'Day_22',\n",
       " 'Day_23',\n",
       " 'Day_24',\n",
       " 'Day_25',\n",
       " 'Day_26',\n",
       " 'Day_27',\n",
       " 'Day_28',\n",
       " 'Day_29',\n",
       " 'Day_30',\n",
       " 'Day_31',\n",
       " 'DayOfWeek_0',\n",
       " 'DayOfWeek_1',\n",
       " 'DayOfWeek_2',\n",
       " 'DayOfWeek_3',\n",
       " 'DayOfWeek_4',\n",
       " 'DayOfWeek_5',\n",
       " 'DayOfWeek_6',\n",
       " 'WeekOfYear_1',\n",
       " 'WeekOfYear_2',\n",
       " 'WeekOfYear_3',\n",
       " 'WeekOfYear_4',\n",
       " 'WeekOfYear_5',\n",
       " 'WeekOfYear_6',\n",
       " 'WeekOfYear_7',\n",
       " 'WeekOfYear_8',\n",
       " 'WeekOfYear_9',\n",
       " 'WeekOfYear_10',\n",
       " 'WeekOfYear_11',\n",
       " 'WeekOfYear_12',\n",
       " 'WeekOfYear_13',\n",
       " 'WeekOfYear_14',\n",
       " 'WeekOfYear_15',\n",
       " 'WeekOfYear_16',\n",
       " 'WeekOfYear_17',\n",
       " 'WeekOfYear_18',\n",
       " 'WeekOfYear_19',\n",
       " 'WeekOfYear_20',\n",
       " 'WeekOfYear_21',\n",
       " 'WeekOfYear_22',\n",
       " 'WeekOfYear_23',\n",
       " 'WeekOfYear_24',\n",
       " 'WeekOfYear_25',\n",
       " 'WeekOfYear_26',\n",
       " 'WeekOfYear_27',\n",
       " 'WeekOfYear_28',\n",
       " 'WeekOfYear_29',\n",
       " 'WeekOfYear_30',\n",
       " 'WeekOfYear_31',\n",
       " 'WeekOfYear_32',\n",
       " 'WeekOfYear_33',\n",
       " 'WeekOfYear_34',\n",
       " 'WeekOfYear_35',\n",
       " 'WeekOfYear_36',\n",
       " 'WeekOfYear_37',\n",
       " 'WeekOfYear_38',\n",
       " 'WeekOfYear_39',\n",
       " 'WeekOfYear_40',\n",
       " 'WeekOfYear_41',\n",
       " 'WeekOfYear_42',\n",
       " 'WeekOfYear_43',\n",
       " 'WeekOfYear_44',\n",
       " 'WeekOfYear_45',\n",
       " 'WeekOfYear_46',\n",
       " 'WeekOfYear_47',\n",
       " 'WeekOfYear_48',\n",
       " 'WeekOfYear_49',\n",
       " 'WeekOfYear_50',\n",
       " 'WeekOfYear_51',\n",
       " 'WeekOfYear_52',\n",
       " 'CompetitionOpen',\n",
       " 'PromoOpen',\n",
       " 'IsPromoMonth']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train[features].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def toVWFile(data, features, target, fileName):\n",
    "    f = open(fileName, 'wb')\n",
    "    for index, row in data.iterrows():\n",
    "        if target is not None:\n",
    "            f.write(str(target[index]))\n",
    "        f.write(\" | \")\n",
    "        for feature in features:\n",
    "            f.write(feature)\n",
    "            f.write(\":\")\n",
    "            f.write(str(row[feature]))\n",
    "            f.write(\" \")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "# toVWFile(train, features, train.Sales, \"../data/vw_train\")\n",
    "toVWFile(test, features, None, \"../data/vw_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
